# Agent

## åŸºç¡€ä»»åŠ¡

ä½¿ç”¨ Lagent å¤ç°æ–‡æ¡£ä¸­ â€œåˆ¶ä½œä¸€ä¸ªå±äºè‡ªå·±çš„Agentâ€ å’Œ â€œMulti-Agentsåšå®¢å†™ä½œç³»ç»Ÿçš„æ­å»ºâ€ä¸¤éƒ¨åˆ†å†…å®¹ï¼Œè®°å½•å¤ç°è¿‡ç¨‹å¹¶æˆªå›¾ã€‚

è¿™é‡Œæˆ‘ä»¬ä¸¥æ ¼æŒ‰ç…§è¯¾ç¨‹æŒ‡å¼•æ¥åšå³å¯

```
# åˆ›å»ºç¯å¢ƒ
conda create -n lagent python=3.10 -y
# æ¿€æ´»ç¯å¢ƒ
conda activate lagent
# å®‰è£… torch
conda install pytorch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 pytorch-cuda=12.1 -c pytorch -c nvidia -y
# å®‰è£…å…¶ä»–ä¾èµ–åŒ…
pip install termcolor==2.4.0
pip install streamlit==1.39.0
pip install class_registry==2.1.2
pip install datasets==3.1.0
```

å› ä¸ºå®‰è£…è¦èŠ±ä¸€ç‚¹ç‚¹æ—¶é—´ï¼Œæ‰€ä»¥éœ€è¦è€å¿ƒç­‰å¾…
![1734234404544](image/readme/1734234404544.png)

![1734236019545](image/readme/1734236019545.png)

![1734236003324](image/readme/1734236003324.png)

![1734235964180](image/readme/1734235964180.png)

![1734235984023](image/readme/1734235984023.png)

![1734235952912](image/readme/1734235952912.png)

æ¥ä¸‹æ¥å®‰è£…lgent

```
# åˆ›å»ºç›®å½•ä»¥å­˜æ”¾ä»£ç 
mkdir -p /root/agent_camp4
cd /root/agent_camp4
git clone https://github.com/InternLM/lagent.git
cd lagent && git checkout e304e5d && pip install -e . && cd ..
pip install griffe==0.48.0
```

ä¸‹é¢æ˜¯æˆªå›¾ï¼š

![1734236099175](image/readme/1734236099175.png)

è¿™é‡Œæ¥ä¸‹æ¥è¦æ­å»ºä¸€ä¸ªwebdemoã€‚

[ç”³è¯·api](https://internlm.intern-ai.org.cn/api/tokens)å°±è·³è¿‡äº†ï¼Œåæ­£ä¸éš¾çš„ã€‚

ç„¶åç”¨æ–‡æ¡£ç»™æˆ‘ä»¬æä¾›çš„å°±å¯ä»¥ï¼š

```
cd /root/agent_camp4/lagent/examples
touch agent_api_web_demo.py
```

![1734236950108](image/readme/1734236950108.png)

pyæ–‡ä»¶çš„å†…å®¹æ–‡æ¡£å†…ç›´æ¥æä¾›äº†ã€‚

```
import copy
import os
from typing import List
import streamlit as st
from lagent.actions import ArxivSearch
from lagent.prompts.parsers import PluginParser
from lagent.agents.stream import INTERPRETER_CN, META_CN, PLUGIN_CN, AgentForInternLM, get_plugin_prompt
from lagent.llms import GPTAPI

class SessionState:
    """ç®¡ç†ä¼šè¯çŠ¶æ€çš„ç±»ã€‚"""

    def init_state(self):
        """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€å˜é‡ã€‚"""
        st.session_state['assistant'] = []  # åŠ©æ‰‹æ¶ˆæ¯å†å²
        st.session_state['user'] = []  # ç”¨æˆ·æ¶ˆæ¯å†å²
        # åˆå§‹åŒ–æ’ä»¶åˆ—è¡¨
        action_list = [
            ArxivSearch(),
        ]
        st.session_state['plugin_map'] = {action.name: action for action in action_list}
        st.session_state['model_map'] = {}  # å­˜å‚¨æ¨¡å‹å®ä¾‹
        st.session_state['model_selected'] = None  # å½“å‰é€‰å®šæ¨¡å‹
        st.session_state['plugin_actions'] = set()  # å½“å‰æ¿€æ´»æ’ä»¶
        st.session_state['history'] = []  # èŠå¤©å†å²
        st.session_state['api_base'] = None  # åˆå§‹åŒ–API baseåœ°å€

    def clear_state(self):
        """æ¸…é™¤å½“å‰ä¼šè¯çŠ¶æ€ã€‚"""
        st.session_state['assistant'] = []
        st.session_state['user'] = []
        st.session_state['model_selected'] = None


class StreamlitUI:
    """ç®¡ç† Streamlit ç•Œé¢çš„ç±»ã€‚"""

    def __init__(self, session_state: SessionState):
        self.session_state = session_state
        self.plugin_action = []  # å½“å‰é€‰å®šçš„æ’ä»¶
        # åˆå§‹åŒ–æç¤ºè¯
        self.meta_prompt = META_CN
        self.plugin_prompt = PLUGIN_CN
        self.init_streamlit()

    def init_streamlit(self):
        """åˆå§‹åŒ– Streamlit çš„ UI è®¾ç½®ã€‚"""
        st.set_page_config(
            layout='wide',
            page_title='lagent-web',
            page_icon='./docs/imgs/lagent_icon.png'
        )
        st.header(':robot_face: :blue[Lagent] Web Demo ', divider='rainbow')

    def setup_sidebar(self):
        """è®¾ç½®ä¾§è¾¹æ ï¼Œé€‰æ‹©æ¨¡å‹å’Œæ’ä»¶ã€‚"""
        # æ¨¡å‹åç§°å’Œ API Base è¾“å…¥æ¡†
        model_name = st.sidebar.text_input('æ¨¡å‹åç§°ï¼š', value='internlm2.5-latest')
        
        # ================================== ç¡…åŸºæµåŠ¨çš„API ==================================
        # æ³¨æ„ï¼Œå¦‚æœé‡‡ç”¨ç¡…åŸºæµåŠ¨APIï¼Œæ¨¡å‹åç§°éœ€è¦æ›´æ”¹ä¸ºï¼šinternlm/internlm2_5-7b-chat æˆ–è€… internlm/internlm2_5-20b-chat
        # api_base = st.sidebar.text_input(
        #     'API Base åœ°å€ï¼š', value='https://api.siliconflow.cn/v1/chat/completions'
        # )
        # ================================== æµ¦è¯­å®˜æ–¹çš„API ==================================
        api_base = st.sidebar.text_input(
            'API Base åœ°å€ï¼š', value='https://internlm-chat.intern-ai.org.cn/puyu/api/v1/chat/completions'
        )
        # ==================================================================================
        # æ’ä»¶é€‰æ‹©
        plugin_name = st.sidebar.multiselect(
            'æ’ä»¶é€‰æ‹©',
            options=list(st.session_state['plugin_map'].keys()),
            default=[],
        )

        # æ ¹æ®é€‰æ‹©çš„æ’ä»¶ç”Ÿæˆæ’ä»¶æ“ä½œåˆ—è¡¨
        self.plugin_action = [st.session_state['plugin_map'][name] for name in plugin_name]

        # åŠ¨æ€ç”Ÿæˆæ’ä»¶æç¤º
        if self.plugin_action:
            self.plugin_prompt = get_plugin_prompt(self.plugin_action)

        # æ¸…ç©ºå¯¹è¯æŒ‰é’®
        if st.sidebar.button('æ¸…ç©ºå¯¹è¯', key='clear'):
            self.session_state.clear_state()

        return model_name, api_base, self.plugin_action

    def initialize_chatbot(self, model_name, api_base, plugin_action):
        """åˆå§‹åŒ– GPTAPI å®ä¾‹ä½œä¸º chatbotã€‚"""
        token = os.getenv("token")
        if not token:
            st.error("æœªæ£€æµ‹åˆ°ç¯å¢ƒå˜é‡ `token`ï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œä¾‹å¦‚ `export token='your_token_here'` åé‡æ–°è¿è¡Œ Xï¹X")
            st.stop()  # åœæ­¢è¿è¡Œåº”ç”¨
            
        # åˆ›å»ºå®Œæ•´çš„ meta_promptï¼Œä¿ç•™åŸå§‹ç»“æ„å¹¶åŠ¨æ€æ’å…¥ä¾§è¾¹æ é…ç½®
        meta_prompt = [
            {"role": "system", "content": self.meta_prompt, "api_role": "system"},
            {"role": "user", "content": "", "api_role": "user"},
            {"role": "assistant", "content": self.plugin_prompt, "api_role": "assistant"},
            {"role": "environment", "content": "", "api_role": "environment"}
        ]

        api_model = GPTAPI(
            model_type=model_name,
            api_base=api_base,
            key=token,  # ä»ç¯å¢ƒå˜é‡ä¸­è·å–æˆæƒä»¤ç‰Œ
            meta_template=meta_prompt,
            max_new_tokens=512,
            temperature=0.8,
            top_p=0.9
        )
        return api_model

    def render_user(self, prompt: str):
        """æ¸²æŸ“ç”¨æˆ·è¾“å…¥å†…å®¹ã€‚"""
        with st.chat_message('user'):
            st.markdown(prompt)

    def render_assistant(self, agent_return):
        """æ¸²æŸ“åŠ©æ‰‹å“åº”å†…å®¹ã€‚"""
        with st.chat_message('assistant'):
            content = getattr(agent_return, "content", str(agent_return))
            st.markdown(content if isinstance(content, str) else str(content))


def main():
    """ä¸»å‡½æ•°ï¼Œè¿è¡Œ Streamlit åº”ç”¨ã€‚"""
    if 'ui' not in st.session_state:
        session_state = SessionState()
        session_state.init_state()
        st.session_state['ui'] = StreamlitUI(session_state)
    else:
        st.set_page_config(
            layout='wide',
            page_title='lagent-web',
            page_icon='./docs/imgs/lagent_icon.png'
        )
        st.header(':robot_face: :blue[Lagent] Web Demo ', divider='rainbow')

    # è®¾ç½®ä¾§è¾¹æ å¹¶è·å–æ¨¡å‹å’Œæ’ä»¶ä¿¡æ¯
    model_name, api_base, plugin_action = st.session_state['ui'].setup_sidebar()
    plugins = [dict(type=f"lagent.actions.{plugin.__class__.__name__}") for plugin in plugin_action]

    if (
        'chatbot' not in st.session_state or
        model_name != st.session_state['chatbot'].model_type or
        'last_plugin_action' not in st.session_state or
        plugin_action != st.session_state['last_plugin_action'] or
        api_base != st.session_state['api_base']    
    ):
        # æ›´æ–° Chatbot
        st.session_state['chatbot'] = st.session_state['ui'].initialize_chatbot(model_name, api_base, plugin_action)
        st.session_state['last_plugin_action'] = plugin_action  # æ›´æ–°æ’ä»¶çŠ¶æ€
        st.session_state['api_base'] = api_base  # æ›´æ–° API Base åœ°å€

        # åˆå§‹åŒ– AgentForInternLM
        st.session_state['agent'] = AgentForInternLM(
            llm=st.session_state['chatbot'],
            plugins=plugins,
            output_format=dict(
                type=PluginParser,
                template=PLUGIN_CN,
                prompt=get_plugin_prompt(plugin_action)
            )
        )
        # æ¸…ç©ºå¯¹è¯å†å²
        st.session_state['session_history'] = []

    if 'agent' not in st.session_state:
        st.session_state['agent'] = None

    agent = st.session_state['agent']
    for prompt, agent_return in zip(st.session_state['user'], st.session_state['assistant']):
        st.session_state['ui'].render_user(prompt)
        st.session_state['ui'].render_assistant(agent_return)

    # å¤„ç†ç”¨æˆ·è¾“å…¥
    if user_input := st.chat_input(''):
        st.session_state['ui'].render_user(user_input)

        # è°ƒç”¨æ¨¡å‹æ—¶ç¡®ä¿ä¾§è¾¹æ çš„ç³»ç»Ÿæç¤ºè¯å’Œæ’ä»¶æç¤ºè¯ç”Ÿæ•ˆ
        res = agent(user_input, session_id=0)
        st.session_state['ui'].render_assistant(res)

        # æ›´æ–°ä¼šè¯çŠ¶æ€
        st.session_state['user'].append(user_input)
        st.session_state['assistant'].append(copy.deepcopy(res))

    st.session_state['last_status'] = None


if __name__ == '__main__':
    main()
```

![1734236971463](image/readme/1734236971463.png)

```
export token='your_token_here'
streamlit run agent_api_web_demo.py
```

![1734237080429](image/readme/1734237080429.png)

æµ‹è¯•ä¸€ä¸‹ï¼Œç«¯å£æ˜ å°„åšå¥½å³å¯

```
 ssh -p 44044 root@ssh.intern-ai.org.cn -CNg -L 8501:127.0.0.1:8501 -o StrictHostKeyChecking=no
```

![1734237258429](image/readme/1734237258429.png)


å®æµ‹å¦‚å›¾ï¼š
![1734237314267](image/readme/1734237314267.png)

æˆ‘ä»¬æ— æ³•æŸ¥è¯¢åˆ°å¤©æ°”ï¼Œæ¥ä¸‹æ¥æŒ‰ç…§æŒ‡å¼•ï¼Œæˆ‘ä»¬éœ€è¦æ³¨å†Œä¸€ä¸ªå’Œé£å¤©æ°”çš„è´¦å·ï¼ˆè¿™ä¸€æ­¥å¿«è¿›äº†ï¼Œæ²¡æœ‰æˆªå›¾å“ˆï¼‰

æ¥ä¸‹æ¥æˆ‘ä»¬è¿›å…¥æ§åˆ¶å°ï¼Œç”³è¯·ä¸€ä¸ªå…è´¹çš„api
![1734237601079](image/readme/1734237601079.png)

å¾—åˆ°äº†æˆ‘ä»¬çš„apiï¼š
![1734237660843](image/readme/1734237660843.png)



ç”Ÿæˆä¸€ä¸ªæ–°çš„æ–‡ä»¶ï¼š

```
cd /root/agent_camp4/lagent/lagent/actions
touch weather_query.py
```

åœ¨è¿™ä¸ªpyæ–‡ä»¶ä¸­è¾“å…¥ä»¥ä¸‹å†…å®¹ï¼š

```
import os
import requests
from lagent.actions.base_action import BaseAction, tool_api
from lagent.schema import ActionReturn, ActionStatusCode

class WeatherQuery(BaseAction):
    def __init__(self):
        super().__init__()
        self.api_key = os.getenv("weather_token")
        print(self.api_key)
        if not self.api_key:
            raise EnvironmentError("æœªæ‰¾åˆ°ç¯å¢ƒå˜é‡ 'token'ã€‚è¯·è®¾ç½®ä½ çš„å’Œé£å¤©æ°” API Key åˆ° 'weather_token' ç¯å¢ƒå˜é‡ä¸­ï¼Œæ¯”å¦‚export weather_token='xxx' ")

    @tool_api
    def run(self, location: str) -> dict:
        """
        æŸ¥è¯¢å®æ—¶å¤©æ°”ä¿¡æ¯ã€‚

        Args:
            location (str): è¦æŸ¥è¯¢çš„åœ°ç‚¹åç§°ã€LocationID æˆ–ç»çº¬åº¦åæ ‡ï¼ˆå¦‚ "101010100" æˆ– "116.41,39.92"ï¼‰ã€‚

        Returns:
            dict: åŒ…å«å¤©æ°”ä¿¡æ¯çš„å­—å…¸
                * location: åœ°ç‚¹åç§°
                * weather: å¤©æ°”çŠ¶å†µ
                * temperature: å½“å‰æ¸©åº¦
                * wind_direction: é£å‘
                * wind_speed: é£é€Ÿï¼ˆå…¬é‡Œ/å°æ—¶ï¼‰
                * humidity: ç›¸å¯¹æ¹¿åº¦ï¼ˆ%ï¼‰
                * report_time: æ•°æ®æŠ¥å‘Šæ—¶é—´
        """
        try:
            # å¦‚æœ location ä¸æ˜¯åæ ‡æ ¼å¼ï¼ˆä¾‹å¦‚ "116.41,39.92"ï¼‰ï¼Œåˆ™è°ƒç”¨ GeoAPI è·å– LocationID
            if not ("," in location and location.replace(",", "").replace(".", "").isdigit()):
                # ä½¿ç”¨ GeoAPI è·å– LocationID
                geo_url = f"https://geoapi.qweather.com/v2/city/lookup?location={location}&key={self.api_key}"
                geo_response = requests.get(geo_url)
                geo_data = geo_response.json()

                if geo_data.get("code") != "200" or not geo_data.get("location"):
                    raise Exception(f"GeoAPI è¿”å›é”™è¯¯ç ï¼š{geo_data.get('code')} æˆ–æœªæ‰¾åˆ°ä½ç½®")

                location = geo_data["location"][0]["id"]

            # æ„å»ºå¤©æ°”æŸ¥è¯¢çš„ API è¯·æ±‚ URL
            weather_url = f"https://devapi.qweather.com/v7/weather/now?location={location}&key={self.api_key}"
            response = requests.get(weather_url)
            data = response.json()

            # æ£€æŸ¥ API å“åº”ç 
            if data.get("code") != "200":
                raise Exception(f"Weather API è¿”å›é”™è¯¯ç ï¼š{data.get('code')}")

            # è§£æå’Œç»„ç»‡å¤©æ°”ä¿¡æ¯
            weather_info = {
                "location": location,
                "weather": data["now"]["text"],
                "temperature": data["now"]["temp"] + "Â°C", 
                "wind_direction": data["now"]["windDir"],
                "wind_speed": data["now"]["windSpeed"] + " km/h",  
                "humidity": data["now"]["humidity"] + "%",
                "report_time": data["updateTime"]
            }

            return {"result": weather_info}

        except Exception as exc:
            return ActionReturn(
                errmsg=f"WeatherQuery å¼‚å¸¸ï¼š{exc}",
                state=ActionStatusCode.HTTP_ERROR
            )
```

å¦å¤–å°†è‡ªå·±çš„apiå¯¼å…¥åˆ°è‡ªå·±çš„ç¯å¢ƒä¸­å»ã€‚

```
export weather_token='your_token_here'
```

åŒæ—¶åœ¨__init__.pyä¸­ä¿®æ”¹ä¸ºä»¥ä¸‹å†…å®¹ï¼š
```
from .action_executor import ActionExecutor, AsyncActionExecutor
from .arxiv_search import ArxivSearch, AsyncArxivSearch
from .base_action import BaseAction, tool_api
from .bing_map import AsyncBINGMap, BINGMap
from .builtin_actions import FinishAction, InvalidAction, NoAction
from .google_scholar_search import AsyncGoogleScholar, GoogleScholar
from .google_search import AsyncGoogleSearch, GoogleSearch
from .ipython_interactive import AsyncIPythonInteractive, IPythonInteractive
from .ipython_interpreter import AsyncIPythonInterpreter, IPythonInterpreter
from .ipython_manager import IPythonInteractiveManager
from .parser import BaseParser, JsonParser, TupleParser
from .ppt import PPT, AsyncPPT
from .python_interpreter import AsyncPythonInterpreter, PythonInterpreter
from .web_browser import AsyncWebBrowser, WebBrowser
from .weather_query import WeatherQuery

__all__ = [
    'BaseAction', 'ActionExecutor', 'AsyncActionExecutor', 'InvalidAction',
    'FinishAction', 'NoAction', 'BINGMap', 'AsyncBINGMap', 'ArxivSearch',
    'AsyncArxivSearch', 'GoogleSearch', 'AsyncGoogleSearch', 'GoogleScholar',
    'AsyncGoogleScholar', 'IPythonInterpreter', 'AsyncIPythonInterpreter',
    'IPythonInteractive', 'AsyncIPythonInteractive',
    'IPythonInteractiveManager', 'PythonInterpreter', 'AsyncPythonInterpreter',
    'PPT', 'AsyncPPT', 'WebBrowser', 'AsyncWebBrowser', 'BaseParser',
    'JsonParser', 'TupleParser', 'tool_api', 'WeatherQuery'
]
```
![1734237873981](image/readme/1734237873981.png)

æˆ‘ä»¬å†å¯¹ä¹‹å‰çš„`agent_api_web_demo.py`ä½œå‡ºä»¥ä¸‹ä¿®æ”¹ï¼š
![1734238154136](image/readme/1734238154136.png)

æ¥ä¸‹æ¥å›åˆ°`examples`æ–‡ä»¶å¤¹é‡Œï¼Œç„¶åé‡æ–°è¿è¡Œã€‚
![1734238261758](image/readme/1734238261758.png)


å¯ä»¥çœ‹åˆ°ï¼Œå¤©æ°”èƒ½å¤ŸæŸ¥åˆ°äº†~
![1734238362229](image/readme/1734238362229.png)

æ¥ä¸‹æ¥æˆ‘ä»¬ç»“æŸæ‰è¿™ä¸ªpyæ–‡ä»¶ï¼Œç›´æ¥å®Œæˆä¸‹ä¸€ä¸ªã€‚
åœ¨åŒè·¯å¾„ä¸‹ç›´æ¥å¼€ä¸€ä¸ªæ–°çš„pyæ–‡ä»¶å³å¯ï¼š
![1734238511446](image/readme/1734238511446.png)

å…·ä½“å†…å®¹å¦‚ä¸‹ï¼š
```
import os
import asyncio
import json
import re
import requests
import streamlit as st

from lagent.agents import Agent
from lagent.prompts.parsers import PluginParser
from lagent.agents.stream import PLUGIN_CN, get_plugin_prompt
from lagent.schema import AgentMessage
from lagent.actions import ArxivSearch
from lagent.hooks import Hook
from lagent.llms import GPTAPI

YOUR_TOKEN_HERE = os.getenv("token")
if not YOUR_TOKEN_HERE:
    raise EnvironmentError("æœªæ‰¾åˆ°ç¯å¢ƒå˜é‡ 'token'ï¼Œè¯·è®¾ç½®åå†è¿è¡Œç¨‹åºã€‚")

# Hookç±»ï¼Œç”¨äºå¯¹æ¶ˆæ¯æ·»åŠ å‰ç¼€
class PrefixedMessageHook(Hook):
    def __init__(self, prefix, senders=None):
        """
        åˆå§‹åŒ–Hook
        :param prefix: æ¶ˆæ¯å‰ç¼€
        :param senders: æŒ‡å®šå‘é€è€…åˆ—è¡¨
        """
        self.prefix = prefix
        self.senders = senders or []

    def before_agent(self, agent, messages, session_id):
        """
        åœ¨ä»£ç†å¤„ç†æ¶ˆæ¯å‰ä¿®æ”¹æ¶ˆæ¯å†…å®¹
        :param agent: å½“å‰ä»£ç†
        :param messages: æ¶ˆæ¯åˆ—è¡¨
        :param session_id: ä¼šè¯ID
        """
        for message in messages:
            if message.sender in self.senders:
                message.content = self.prefix + message.content

class AsyncBlogger:
    """åšå®¢ç”Ÿæˆç±»ï¼Œæ•´åˆå†™ä½œè€…å’Œæ‰¹è¯„è€…ã€‚"""

    def __init__(self, model_type, api_base, writer_prompt, critic_prompt, critic_prefix='', max_turn=2):
        """
        åˆå§‹åŒ–åšå®¢ç”Ÿæˆå™¨
        :param model_type: æ¨¡å‹ç±»å‹
        :param api_base: API åŸºåœ°å€
        :param writer_prompt: å†™ä½œè€…æç¤ºè¯
        :param critic_prompt: æ‰¹è¯„è€…æç¤ºè¯
        :param critic_prefix: æ‰¹è¯„æ¶ˆæ¯å‰ç¼€
        :param max_turn: æœ€å¤§è½®æ¬¡
        """
        self.model_type = model_type
        self.api_base = api_base
        self.llm = GPTAPI(
            model_type=model_type,
            api_base=api_base,
            key=YOUR_TOKEN_HERE,
            max_new_tokens=4096,
        )
        self.plugins = [dict(type='lagent.actions.ArxivSearch')]
        self.writer = Agent(
            self.llm,
            writer_prompt,
            name='å†™ä½œè€…',
            output_format=dict(
                type=PluginParser,
                template=PLUGIN_CN,
                prompt=get_plugin_prompt(self.plugins)
            )
        )
        self.critic = Agent(
            self.llm,
            critic_prompt,
            name='æ‰¹è¯„è€…',
            hooks=[PrefixedMessageHook(critic_prefix, ['å†™ä½œè€…'])]
        )
        self.max_turn = max_turn

    async def forward(self, message: AgentMessage, update_placeholder):
        """
        æ‰§è¡Œå¤šé˜¶æ®µåšå®¢ç”Ÿæˆæµç¨‹
        :param message: åˆå§‹æ¶ˆæ¯
        :param update_placeholder: Streamlitå ä½ç¬¦
        :return: æœ€ç»ˆä¼˜åŒ–çš„åšå®¢å†…å®¹
        """
        step1_placeholder = update_placeholder.container()
        step2_placeholder = update_placeholder.container()
        step3_placeholder = update_placeholder.container()

        # ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆåˆå§‹å†…å®¹
        step1_placeholder.markdown("**Step 1: ç”Ÿæˆåˆå§‹å†…å®¹...**")
        message = self.writer(message)
        if message.content:
            step1_placeholder.markdown(f"**ç”Ÿæˆçš„åˆå§‹å†…å®¹**:\n\n{message.content}")
        else:
            step1_placeholder.markdown("**ç”Ÿæˆçš„åˆå§‹å†…å®¹ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ç”Ÿæˆé€»è¾‘ã€‚**")

        # ç¬¬äºŒæ­¥ï¼šæ‰¹è¯„è€…æä¾›åé¦ˆ
        step2_placeholder.markdown("**Step 2: æ‰¹è¯„è€…æ­£åœ¨æä¾›åé¦ˆå’Œæ–‡çŒ®æ¨è...**")
        message = self.critic(message)
        if message.content:
            # è§£ææ‰¹è¯„è€…åé¦ˆ
            suggestions = re.search(r"1\. æ‰¹è¯„å»ºè®®ï¼š\n(.*?)2\. æ¨èçš„å…³é”®è¯ï¼š", message.content, re.S)
            keywords = re.search(r"2\. æ¨èçš„å…³é”®è¯ï¼š\n- (.*)", message.content)
            feedback = suggestions.group(1).strip() if suggestions else "æœªæä¾›æ‰¹è¯„å»ºè®®"
            keywords = keywords.group(1).strip() if keywords else "æœªæä¾›å…³é”®è¯"

            # Arxiv æ–‡çŒ®æŸ¥è¯¢
            arxiv_search = ArxivSearch()
            arxiv_results = arxiv_search.get_arxiv_article_information(keywords)

            # æ˜¾ç¤ºæ‰¹è¯„å†…å®¹å’Œæ–‡çŒ®æ¨è
            message.content = f"**æ‰¹è¯„å»ºè®®**:\n{feedback}\n\n**æ¨èçš„æ–‡çŒ®**:\n{arxiv_results}"
            step2_placeholder.markdown(f"**æ‰¹è¯„å’Œæ–‡çŒ®æ¨è**:\n\n{message.content}")
        else:
            step2_placeholder.markdown("**æ‰¹è¯„å†…å®¹ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ‰¹è¯„é€»è¾‘ã€‚**")

        # ç¬¬ä¸‰æ­¥ï¼šå†™ä½œè€…æ ¹æ®åé¦ˆä¼˜åŒ–å†…å®¹
        step3_placeholder.markdown("**Step 3: æ ¹æ®åé¦ˆæ”¹è¿›å†…å®¹...**")
        improvement_prompt = AgentMessage(
            sender="critic",
            content=(
                f"æ ¹æ®ä»¥ä¸‹æ‰¹è¯„å»ºè®®å’Œæ¨èæ–‡çŒ®å¯¹å†…å®¹è¿›è¡Œæ”¹è¿›ï¼š\n\n"
                f"æ‰¹è¯„å»ºè®®ï¼š\n{feedback}\n\n"
                f"æ¨èæ–‡çŒ®ï¼š\n{arxiv_results}\n\n"
                f"è¯·ä¼˜åŒ–åˆå§‹å†…å®¹ï¼Œä½¿å…¶æ›´åŠ æ¸…æ™°ã€ä¸°å¯Œï¼Œå¹¶ç¬¦åˆä¸“ä¸šæ°´å‡†ã€‚"
            ),
        )
        message = self.writer(improvement_prompt)
        if message.content:
            step3_placeholder.markdown(f"**æœ€ç»ˆä¼˜åŒ–çš„åšå®¢å†…å®¹**:\n\n{message.content}")
        else:
            step3_placeholder.markdown("**æœ€ç»ˆä¼˜åŒ–çš„åšå®¢å†…å®¹ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ç”Ÿæˆé€»è¾‘ã€‚**")

        return message

def setup_sidebar():
    """è®¾ç½®ä¾§è¾¹æ ï¼Œé€‰æ‹©æ¨¡å‹ã€‚"""
    model_name = st.sidebar.text_input('æ¨¡å‹åç§°ï¼š', value='internlm2.5-latest')
    api_base = st.sidebar.text_input(
        'API Base åœ°å€ï¼š', value='https://internlm-chat.intern-ai.org.cn/puyu/api/v1/chat/completions'
    )
    
    return model_name, api_base
    
def main():
    """
    ä¸»å‡½æ•°ï¼šæ„å»ºStreamlitç•Œé¢å¹¶å¤„ç†ç”¨æˆ·äº¤äº’
    """
    st.set_page_config(layout='wide', page_title='Lagent Web Demo', page_icon='ğŸ¤–')
    st.title("å¤šä»£ç†åšå®¢ä¼˜åŒ–åŠ©æ‰‹")

    model_type, api_base = setup_sidebar()
    topic = st.text_input('è¾“å…¥ä¸€ä¸ªè¯é¢˜ï¼š', 'Self-Supervised Learning')
    generate_button = st.button('ç”Ÿæˆåšå®¢å†…å®¹')

    if (
        'blogger' not in st.session_state or
        st.session_state['model_type'] != model_type or
        st.session_state['api_base'] != api_base
    ):
        st.session_state['blogger'] = AsyncBlogger(
            model_type=model_type,
            api_base=api_base,
            writer_prompt="ä½ æ˜¯ä¸€ä½ä¼˜ç§€çš„AIå†…å®¹å†™ä½œè€…ï¼Œè¯·æ’°å†™ä¸€ç¯‡æœ‰å¸å¼•åŠ›ä¸”ä¿¡æ¯ä¸°å¯Œçš„åšå®¢å†…å®¹ã€‚",
            critic_prompt="""
                ä½œä¸ºä¸€ä½ä¸¥è°¨çš„æ‰¹è¯„è€…ï¼Œè¯·ç»™å‡ºå»ºè®¾æ€§çš„æ‰¹è¯„å’Œæ”¹è¿›å»ºè®®ï¼Œå¹¶åŸºäºç›¸å…³ä¸»é¢˜ä½¿ç”¨å·²æœ‰çš„å·¥å…·æ¨èä¸€äº›å‚è€ƒæ–‡çŒ®ï¼Œæ¨èçš„å…³é”®è¯åº”è¯¥æ˜¯è‹±è¯­å½¢å¼ï¼Œç®€æ´ä¸”åˆ‡é¢˜ã€‚
                è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼æä¾›åé¦ˆï¼š
                1. æ‰¹è¯„å»ºè®®ï¼š
                - ï¼ˆå…·ä½“å»ºè®®ï¼‰
                2. æ¨èçš„å…³é”®è¯ï¼š
                - ï¼ˆå…³é”®è¯1, å…³é”®è¯2, ...ï¼‰
            """,
            critic_prefix="è¯·æ‰¹è¯„ä»¥ä¸‹å†…å®¹ï¼Œå¹¶æä¾›æ”¹è¿›å»ºè®®ï¼š\n\n"
        )
        st.session_state['model_type'] = model_type
        st.session_state['api_base'] = api_base

    if generate_button:
        update_placeholder = st.empty()

        async def run_async_blogger():
            message = AgentMessage(
                sender='user',
                content=f"è¯·æ’°å†™ä¸€ç¯‡å…³äº{topic}çš„åšå®¢æ–‡ç« ï¼Œè¦æ±‚è¡¨è¾¾ä¸“ä¸šï¼Œç”ŸåŠ¨æœ‰è¶£ï¼Œå¹¶ä¸”æ˜“äºç†è§£ã€‚"
            )
            result = await st.session_state['blogger'].forward(message, update_placeholder)
            return result

        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(run_async_blogger())

if __name__ == '__main__':
    main()
```

æ¥ä¸‹æ¥è¿è¡Œå³å¯ã€‚
![1734238632785](image/readme/1734238632785.png)
![1734238649805](image/readme/1734238649805.png)
![1734238668534](image/readme/1734238668534.png)
å®Œæˆã€‚
